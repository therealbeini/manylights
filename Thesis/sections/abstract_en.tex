%% LaTeX2e class for student theses
%% sections/abstract_en.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.3.3, 2018-04-17

\Abstract

When rendering complex scenes with a high requirement for image quality, path tracing has been the most popular tool in the last few years. Compared to scanline techniques like rasterization, path tracing offers a higher image quality with the trade-off of longer rendering times. That is the main reason why path tracing is the preferred algorithm when creating pictures or videos in beforehand. However, the rendering times of animated films like the in 2014 released \textit{Big Hero 6}, have exploded with more and more complicated scenes. Disney released statistics showing the movie was rendered with 1.1 million computational hours per day, distributed on a 55.000-core computer across four geographic locations. If the rendering times are so long, they are important even when the system does not need to provide the rendering of the movie in real-time. \textit{Big Hero 6} plays in a city called San Fransokyo. It contains around 83.000 buildings, 215.000 streetlights and 100.000 vehicles. At nighttime, all these objects can be light sources, which leads to a gigantic number of emitters. When rendering with path tracing, we have to light certain points of the scene with light sources. With this huge number of lights, it is clearly not practical to calculate the lighting of each point for every single light in the scene. Also, choosing random light sources will definitely not achieve the image quality we want for a pleasant user experience in a reasonable time. \cite{BH6}

This work introduces an acceleration structure that allows for faster rendering of scenes with a large number of lights. Instead of choosing a random light source in the scene, we will try to sample lights that have a high contribution to the point to be lighted more often. That way, our algorithm converges faster and the image quality with similar rendering times will be better than using conventional light sampling strategies.