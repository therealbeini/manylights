%% LaTeX2e class for student theses
%% sections/content.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.3.3, 2018-04-17

\chapter{Preliminaries}
\label{ch:preliminaries}

\section{Probability Theory Basics}
\label{ch:preliminaries:ptb}

In this section we will be discussing basic ideas and define certain terms from the probability theory. We will assume that the reader is already familiar with most of the concepts and therefore will only give a short introduction. If the reader struggles following the key parts of this section, he is heavily adviced to read more extensive literature about this subject. We suggest E. T. Jaynes \textit{Probability Theory: The Logic of Science} for this matter. \cite{PTTLS}

\subsection{Random Variable}

A random variable $X$ is a variable whose values are numerical outcomes chosen by a random process. There are discrete random variables, which can only take a countable set of possible outcomes and continuous random variables with an uncountable number of possible results. For instance, flipping a coin would be a random variable drawn from a discrete domain which can only result to heads or tails, while sampling a random direction over a unit sphere can produce infinite different directions. In rendering and particularly in ray tracing, we are often sampling certain directions or light sources in order to illuminate the scene, therefore we will be handling both discrete and continuous random variables, albeit with the latter in the most cases.

The so-called canonical uniform random variable $\xi$ is a special continuous random variable that is especially important for us. Every interval in its domain [0, 1) with equal length are assigned the same probability. This random variable makes it very easy to generate samples from arbitrary distributions. For example, if we would need to sample a direction to estimate the incident lighting on a point, we could draw two samples from $\xi$ and scale these two values with appropriate transformations so they reflect the polar coordinates of direction to sample.

\subsection{Probability Density Function}

For continuous random variables, probability density functions (PDF) illustrate how the possible outcomes of the random experiment are distributed across the domain. They must be nonnegative and integrate to 1 over the domain. $p:D \rightarrow \mathbb{R}$ is a pdf when
\begin{equation}
\int_{D}p(x)\mathrm{d}x = 1.
\end{equation}
Integrating over a certain interval $[a, b]$ gives the possibility that the random experiment returns a result that lies inside of given interval:
\begin{equation}
\int_{a}^{b}p(x)\mathrm{d}x = P(x \in [a, b])
\end{equation}
It is evident, that $P(x \in [a, a]) = 0$ which reflects the fundamental idea of continuous random variables: The possibility of getting a sample that exactly equals a certain number is zero. Therefore, PDFs are only meaningful when regarded over a interval and not over a single point.

\subsection{Expected Values and Variance}

As the name already indicates, the expected value $E_p[f(x)]$ of a function $f$ and a distribution $p$ specifies the average value of the function after getting a large amount of samples according to the distribution function $p(x)$. Over a certain domain $D$, the expected value is defined as
\begin{equation}
E_p[f(x)] = \int_{D}f(x)p(x)\mathrm{d}x.
\end{equation}

The variance defines a measure that illustrates the distance between the actual sample values and their average value. Formally, it is defined by the expectation of the squared deviation of the function from its expected value:
\begin{equation}
V[f(x)] = E[(f(x) - E[f(x)])^2]
\end{equation}
When we talk about Monto Carlo Intergration later, the variance is a strong indicator of the quality of the PDF we chose. The main part of this thesis will be to minimize the variance of light sampling methods.

\section{Monte Carlo Integration}
\label{ch:preliminaries:mci}

\section{Importance Sampling}
\label{ch:preliminaries:is}

\section{Multiple Importance Sampling}
\label{ch:preliminaries:mis}

\section{Bounding Volume Hierarchies}
\label{sec:preliminaries:bvh}

\section{Surface Area Heuristics}
\label{sec:preliminaries:sah}

\section{The algorithms for comparison}
\label{sec:preliminaries:com}